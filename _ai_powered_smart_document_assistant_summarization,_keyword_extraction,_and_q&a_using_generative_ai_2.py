# -*- coding: utf-8 -*-
""""AI-Powered Smart Document Assistant: Summarization, Keyword Extraction, and Q&A using Generative AI 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlk9V5cwh_yo9YB5Wn4ARr3z9oZEuDy3
"""



# app.py
import streamlit as st
from PyPDF2 import PdfReader
from docx import Document
from transformers import pipeline
from keybert import KeyBERT
from sentence_transformers import SentenceTransformer
import os

# -----------------------------
# Helper functions
# -----------------------------
def extract_text(file):
    if file.type == "application/pdf":
        pdf = PdfReader(file)
        text = ""
        for page in pdf.pages:
            text += page.extract_text()
        return text
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = Document(file)
        text = "\n".join([para.text for para in doc.paragraphs])
        return text
    elif file.type == "text/plain":
        return file.read().decode("utf-8")
    else:
        return ""

def clean_text(text):
    return text.replace("\n", " ").strip()

# -----------------------------
# Load AI models
# -----------------------------
@st.cache_resource
def load_models():
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    qa_pipeline = pipeline("question-answering", model="distilbert-base-cased-distilled-squad")
    kw_model = KeyBERT(model=SentenceTransformer('all-MiniLM-L6-v2'))
    return summarizer, qa_pipeline, kw_model

summarizer, qa_pipeline, kw_model = load_models()

# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="AI Document Assistant", layout="wide")
st.title("üìù AI-Powered Smart Document Assistant")

# Upload multiple documents
uploaded_files = st.file_uploader(
    "Upload PDF, DOCX, or TXT files",
    type=["pdf", "docx", "txt"],
    accept_multiple_files=True
)

if uploaded_files:
    docs = {}
    for file in uploaded_files:
        text = extract_text(file)
        text = clean_text(text)
        docs[file.name] = text

    # Select document
    doc_choice = st.selectbox("Select a document", list(docs.keys()))
    selected_text = docs[doc_choice]

    # Tabs for Summary, Keywords, Q&A
    tab1, tab2, tab3 = st.tabs(["Summary", "Keywords", "Q&A"])

    # -----------------------------
    # Summary Tab
    # -----------------------------
    with tab1:
        st.header("üìÑ Summary")
        if st.button("Generate Summary"):
            try:
                summary = summarizer(selected_text, max_length=250, min_length=50, do_sample=False)[0]['summary_text']
                st.success(summary)
            except Exception as e:
                st.error(f"Error generating summary: {e}")

    # -----------------------------
    # Keywords Tab
    # -----------------------------
    with tab2:
        st.header("üîë Keywords")
        if st.button("Extract Keywords"):
            try:
                keywords = kw_model.extract_keywords(selected_text, top_n=10)
                st.success(", ".join([kw[0] for kw in keywords]))
            except Exception as e:
                st.error(f"Error extracting keywords: {e}")

    # -----------------------------
    # Q&A Tab
    # -----------------------------
    with tab3:
        st.header("‚ùì Ask a Question")
        question = st.text_input("Type your question here:")
        if question and st.button("Get Answer"):
            try:
                answer = qa_pipeline(question=question, context=selected_text)
                st.success(answer['answer'])
            except Exception as e:
                st.error(f"Error answering question: {e}")
